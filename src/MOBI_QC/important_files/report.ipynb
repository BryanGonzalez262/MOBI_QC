{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reportlab.lib.styles import ParagraphStyle, getSampleStyleSheet\n",
    "from reportlab.lib.pagesizes import A4\n",
    "from reportlab.lib import colors\n",
    "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle, Image\n",
    "from reportlab.lib.utils import ImageReader\n",
    "import os\n",
    "import mne\n",
    "import json\n",
    "\n",
    "from utils import *\n",
    "from eeg_qc import compute_eeg_pipeline, test_eeg_pipeline\n",
    "from ecg_qc import ecg_qc \n",
    "from eda_qc import eda_qc\n",
    "from rsp_qc import *\n",
    "from mic_qc import *\n",
    "from lsl_problem import *\n",
    "from et_qc import *\n",
    "from webcam_qc import *\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = \"P5871751\"\n",
    "xdf_filename = f'/Users/bryan.gonzalez/CUNY_subs/sub-{subject}/sub-{subject}_ses-S001_task-CUNY_run-001_mobi.xdf'\n",
    "\n",
    "#subject = \"P5182010\"\n",
    "#xdf_filename = f'/Users/camilla.strauss/Desktop/CUNY_Data/Data/sub-{subject}/sub-{subject}_ses-S001_task-CUNY_run-001_mobi.xdf'\n",
    "\n",
    "#xdf_filename = #Apurva's xdf file\n",
    "\n",
    "video_filename = '/'.join(xdf_filename.split('/')[:-1])+ f'/sub-{subject}_task-CUNY_run-001_video.avi'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_df = import_stim_data(xdf_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. EEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute the eeg vars\n",
    "eeg_vars, raw_cleaned, ica, eeg_df = compute_eeg_pipeline(xdf_filename, \n",
    "                                                          stim_df=stim_df, \n",
    "                                                          task='RestingState')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual Artifact Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = ica.plot_components( title='ICA Components')\n",
    "# Save the ICA plot\n",
    "# change the figure size and save it\n",
    "fig.set_size_inches(10, 8)\n",
    "fig.tight_layout()\n",
    "fig.savefig(f'report_images/{subject}_eeg_ica_components.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ica.plot_properties(raw_cleaned, picks=range(ica.n_components_)) # This exact component number probably won't work if you recompute ICA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ica.plot_overlay(raw_cleaned, picks=[0,3,10,11,13,14,18,19])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ica.exclude = [0,3,10,11,13,14,18,19] # these are the components that we want to exclude\n",
    "ica.apply(raw_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_vars['components_excluded'] = ica.exclude"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_cleaned.annotations.delete([i for i, desc in enumerate(raw_cleaned.annotations.description) if desc == 'blink' or desc == 'BAD_muscle'])\n",
    "fig = raw_cleaned.plot(show_scrollbars=False,\n",
    "                        show_scalebars=False,events=None, start=0, \n",
    "                        duration=200,n_channels=50, scalings=.35e-4, color='k', title='EEG Data after ICA')\n",
    "\n",
    "fig.savefig(f'report_images/{subject}_eeg_cleaned.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "\n",
    "fig = raw_cleaned.plot_psd(fmax=50, average=False, show=True)\n",
    "fig.savefig(f'report_images/{subject}_eeg_cleaned_psd.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_cleaned_pathname = '/'.join(xdf_filename.split('/')[:-1]) + f'/sub-{subject}_ses-S001_task-CUNY_run-001_eeg_clean.fif'\n",
    "raw_cleaned.save(raw_cleaned_pathname, overwrite=True)\n",
    "\n",
    "\n",
    "eeg_print = {\n",
    "    'Bad channels before robust reference': eeg_vars['bad_channels_before'], \n",
    "    'Interpolated channels': eeg_vars['interpolated_channels'], \n",
    "    'Bad channels after interpolation': eeg_vars['bad_channels_after'], \n",
    "    'Percent Good before artifact removal': f\"{eeg_vars['percent_good']:.4}%\",\n",
    "    'Artifactual Components Excluded': ica.exclude\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ECG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[ecg_vars, ecg_plt, ps_df] = ecg_qc(xdf_filename = xdf_filename, stim_df = stim_df, task='RestingState')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_vars.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_print = {\n",
    "    \"Effective sampling rate\": f'{ecg_vars[\"sampling_rate\"]:.4f} Hz', \n",
    "    \"Signal to Noise Ratio\": f'{ecg_vars[\"SNR\"]:.4f} dB',\n",
    "    \"Average heart rate\": f'{ecg_vars[\"average_heart_rate\"]:.4f} bpm',\n",
    "    \"Kurtosis signal quality index (kSQI)\": f'{ecg_vars[\"kurtosis_SQI\"]:.4f}',\n",
    "    \"Power spectrum distribution (pSQI)\": f'{ecg_vars[\"power_spectrum_distribution_SQI\"]:.4f} mVÂ²/Hz',\n",
    "    \"Relative power in baseline (basSQI)\": f'{ecg_vars[\"relative_baseline_power_sqi\"]:.4f}%'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[eda_vars, eda_plt1, eda_plt2, ps_df] = eda_qc(xdf_filename = xdf_filename, stim_df = stim_df, task= 'RestingState')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eda_vars.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eda_print = {\n",
    "    \"Effective sampling rate\": f'{eda_vars[\"sampling_rate\"]:.4f} Hz', \n",
    "    \"Signal to noise ratio\": f'{eda_vars[\"snr\"]:.4f} dB',\n",
    "    \"Signal integrity check\": f'{eda_vars[\"signal_integrity_check\"]:.4f}%',\n",
    "    \"Average skin conductance level\": f'{eda_vars[\"average_scl\"]:.4f} mS',\n",
    "    \"Skin conductance level std\": f'{eda_vars[\"scl_sd\"]:.4f} mS',\n",
    "    \"Skin conductance level coefficient of variation\": f'{eda_vars[\"scl_cv\"]:.4f}%',\n",
    "    \"Average amplitude of skin conductance response\": f'{eda_vars[\"average_scr_amplitude\"]:.4f} mS',\n",
    "    \"Skin conductance response validity\": f'{eda_vars[\"sc_validity\"]:.4f} %' # this will need to be changed to [scr_validity]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. RSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsp_vars, ps_df = rsp_qc(xdf_filename=xdf_filename, stim_df=stim_df, task='RestingState')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsp_print = {\n",
    "    \"Effective sampling rate\": f'{rsp_vars[\"sampling_rate\"]:.4f} Hz', \n",
    "    \"Signal to noise ratio\": f'{rsp_vars[\"rsp_snr\"]:.4f} dB',\n",
    "    \"Breath amplitude mean\": f'{rsp_vars[\"breath_amplitude_mean\"]:.4f} V',\n",
    "    \"Breath amplitude std\": f'{rsp_vars[\"breath_amplitude_std\"]:.4f} V',\n",
    "    \"Breath amplitude range\": f'{rsp_vars[\"breath_amplitude_range\"]} V',\n",
    "    \"Respiration rate mean\": f'{rsp_vars[\"rsp_rate_mean\"]:.4f} bpm',\n",
    "    \"Respiration rate std\": f'{rsp_vars[\"rsp_rate_std\"]:.4f} bpm', \n",
    "    \"Respiration rate range\": f'{rsp_vars[\"rsp_rate_range\"]} bpm', \n",
    "    \"Peak to peak interval mean\": f'{rsp_vars[\"ptp_mean\"]:.4f} sec', \n",
    "    \"Peak to peak interval std\": f'{rsp_vars[\"ptp_std\"]:.4f} sec', \n",
    "    \"Peak to peak interval range\": f'{rsp_vars[\"ptp_range\"]} sec', \n",
    "    \"Baseline drift\": f'{rsp_vars[\"baseline_drift\"]:.4f} V', \n",
    "    \"Autocorrelation at typical breath cycle\": f'{rsp_vars[\"autocorrelation\"]:.4f}'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Mic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mic_vars, mic_df = mic_qc(xdf_filename=xdf_filename, stim_df=stim_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mic_print = {\n",
    "    \"Effective sampling rate\": f'{mic_vars[\"sampling_rate\"]:.4f} Hz', \n",
    "    \"Difference between .wav file and lsl timestamps durations\": f'{mic_vars[\"lsl_wav_duration_diff\"]:.4f} sec', \n",
    "    \"Number of NaN's\": f'{mic_vars[\"num_NaN\"]}',\n",
    "    \"Percent of NaN's\": f'{mic_vars[\"percent_NaN\"]:.4f}%',\n",
    "    \"Mic samples first quartile\": f'{mic_vars[\"quan25\"]:.4f}',\n",
    "    \"Mic samples third quartile\": f'{mic_vars[\"quan75\"]:.4f}',\n",
    "    \"Mic samples std\": f'{mic_vars[\"std\"]:.4f}',\n",
    "    \"Mic samples min\": f'{mic_vars[\"min\"]:.4f}',\n",
    "    \"Mic samples max\": f'{mic_vars[\"max\"]:.4f}'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "webcam_vars, cam_df = webcam_qc(xdf_filename=xdf_filename,\n",
    "                                stim_df=stim_df,\n",
    "                                video_file=video_filename, task='RestingState')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "webcam_print = {\n",
    "    \"Effective sampling rate\": f'{webcam_vars[\"sampling_rate\"]:.4f} Hz', \n",
    "    \"Collected full resting state\": webcam_vars[\"collected_full_RestingState\"], \n",
    "    \"Percent of frames with face detected\": f'{webcam_vars[\"face_perc\"]:.4%}'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "webcam_print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "et_vars, et_df = et_qc(xdf_filename = xdf_filename, stim_df = stim_df, task='RestingState')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "et_print = {\n",
    "    \"Effective sampling rate\": f'{et_vars[\"sampling_rate\"]:.4f} Hz', \n",
    "    \"Flag: all coordinates have the same % validity within each measure (LR, gaze point/origin/diameter)\": et_vars[\"flag1\"], \n",
    "    \"Flag: % of NaNs is the same between coordinate systems (UCS and TBCS (gaze origin) and between UCS and display area (gaze point))\": et_vars[\"flag2\"],\n",
    "    \"Mean difference in percent valid data between right and left eyes\": f'{et_vars[\"LR_mean_diff\"]:.4f}%',\n",
    "    \"Percent of data with gaze point differences of over 0.2 mm\": f'{et_vars[\"percent_over02\"]:.4f}%'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stream Durations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### functions are in utils.py (but should be called in the report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_map = {\n",
    "    'et': et_df,\n",
    "    'ps': ps_df,\n",
    "    'mic': mic_df,\n",
    "    'cam': cam_df\n",
    "    }\n",
    "    # 'eeg': eeg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_vars = {\"Durations of each modality + comparison to expected duration:\": \n",
    "    get_durations(xdf_path=xdf_filename, task='Experiment', df_map = df_map, stim_df = stim_df)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_print = duration_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i wont run these but they are here for reference\n",
    "# get_durations('RestingState', xdf_filename)\n",
    "# get_durations('CampFriend', xdf_filename)\n",
    "# get_durations('SocialTask', xdf_filename)\n",
    "# whole_durations(xdf_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSL Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsl_vars = lsl_problem_qc(xdf_filename, df_map=df_map, stim_df=stim_df, modality_to_plot='et')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsl_print = {\n",
    "    \"Percent of missing data in entire experiment\": lsl_vars[\"percent_loss\"],\n",
    "    \"Percent of missing data before social task offset\": lsl_vars[\"loss_before_social_task\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy = {\n",
    "    'EEG': 'Data preprocessed by performing <b>line noise removal</b>, <b>robust referencing</b>, and <b>bad channel detection/interpolation</b> using PyPrep pipeline. First, the pipeline applies a notch filter at 60 Hz and its harmonics to remove power line noise. Then, it performs <b>robust average referencing</b>, where it detects bad channels, interpolates them using surrounding signals, and computes a median-based reference across EEG channels. This ensures a stable reference even in the presence of noisy electrodes. Independent components analysis (ICA) was then performed to identify and remove ocular and muscle artifacts. The final output is a cleaned EEG dataset with a consistent reference, ready for further analysis.',\n",
    "    'ET': 'In the eye tracking data, gaze origin, gaze point, and pupil diameter are reported, for the left and right eyes. Gaze origin describes the point in 3D space where the gaze vector starts, and is reported in both the user coordinate system (UCS) and the trackbox coordinate system (TBCS). Gaze point describes the spot on the screen where the participant is looking, for each eye. Gaze origin is reported in 3D space in the UCS and the display area. The percent of data for which the distance between the gaze point of the left and right eye is more than 0.2 mm is reported below.',\n",
    "    'ECG': \"The data was processed using the neurokit2 automated pipeline for preprocessing ECG signals. ECG data is cleaned using the default parameters that apply fifth order 0.5 Hz high-pass butterworth filter followed by 50 Hz powerline filtering. Neurokit2 was also used to calculate signal quality indices (SQI) based on Zhao et.al (2018). SQIs calculated were kurtosis (kSQI), power spectrum distribution of QRS wave (pSQI) and relative power in baseline (basSQI). kSQI was calculated using the Fisher's method. pSQI and basSQI were calculated using the Welch method.\",\n",
    "    'EDA': \"Electrodermal Activity (EDA) is measured in microSiemens from a standard EDA sensor. EDA data quality metrics calculated from raw and clean data using neurokit2 python package. The data is processed using the neurokit2 automated pipeline for preprocessing EDA signal. EDA data is cleaned using the default parameters that apply fourth order butterworth filter. Additionally, the automated preprocessing pipeline was used to decompose the EDA signal into the tonic component, Skin Conductance Level (SCL) and the phasic component, Skin Conductance Response (SCR). The decomposition was done using default parameters that perform high-pass filtering with a cutoff frequency of 0.05Hz on EDA signal.\",\n",
    "    'RSP': \"Respiration data is measured in volts from a piezoelectric sensor. Respiration data quality metrics are calculated both from raw and cleaned data, where the neurokit2 package was used to clean the data using the default method of a second order 0.05-3 Hz bandpass Butterworth filter, as in Khodadad et al, 2018. Neurokit2 was also used to extract the peaks and troughs of detected breaths. Respiration rate was calculated using the cross correlation method, which was more consistent to the raw data than the other trough method. Baseline drift was quantified as the standard deviation of the data after applying a lowpass filter to raw data.\",\n",
    "    'MIC': \"For audio data, it is important to confirm that the distribution of microphone samples (see graph below) is relatively centered around 0, with no outlier peaks and no values above 32,000 or below -32,000.\",\n",
    "    'WEBCAM': \"The quality of the webcam data is assessed by checking the percentage of frames where a face is detected. If a face is not detected in more than 50 percent of the frames, it may indicate issues with the recording or participant positioning.\",\n",
    "    'Stream Durations': \"\",\n",
    "    'LSL': \"While the difference between consecutive LSL time stamps are expected to consistently be equal to the inverse of the sampling rate, it was found that there were longer gaps between some LSL time stamps for some data modalities, indicating a potential system or other technical error during data collection. Below, the percentage of missing data for each data modality due to these LSL time stamp gaps is shown. The amount of data in seconds for each modality is also shown below, and each duration is then compared to the expected duration of the experiment.\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second Report with formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modalities and corresponding data\n",
    "metric_names = [\"EEG\", \"ECG\", \"EDA\", \"RSP\", \"MIC\",\"ET\", \"WEBCAM\", \"Stream Durations\", \"LSL\"]\n",
    "metrics_list = [eeg_print, ecg_print, eda_print, rsp_print, mic_print, et_print, webcam_print, duration_print, lsl_print]\n",
    "# metric_names = [\"ECG\", \"EDA\",\"WEBCAM\"]\n",
    "# metrics_list = [ecg_print, eda_print,  webcam_print]\n",
    "\n",
    "# PDF structure\n",
    "parent_folder = xdf_filename.split('mobi')[0]\n",
    "pdf_path = f\"{parent_folder}QCReport.pdf\"\n",
    "doc = SimpleDocTemplate(pdf_path, pagesize=A4)\n",
    "elements = []\n",
    "styles = getSampleStyleSheet()\n",
    "\n",
    "# Define subtitle style if not already done\n",
    "subtitle_style = ParagraphStyle(\n",
    "    name=\"Subtitle\",\n",
    "    parent=styles[\"Heading2\"],\n",
    "    fontSize=14,\n",
    "    leading=16,\n",
    "    textColor=\"gray\",\n",
    "    spaceAfter=12,\n",
    "    alignment=1  # Centered\n",
    ")\n",
    "\n",
    "# page number function\n",
    "def add_page_number(canvas, doc):\n",
    "    page_num = f'{canvas.getPageNumber()}'\n",
    "    canvas.setFont(\"Helvetica\", 9)\n",
    "    canvas.drawRightString(570, 20, page_num)  # (x, y) from bottom-left\n",
    "\n",
    "\n",
    "elements.append(Paragraph(f\"Subject Report: {subject}\", styles[\"Title\"]))\n",
    "elements.append(Paragraph(f\"Collection Date: {get_collection_date(xdf_filename)}\", subtitle_style))\n",
    "elements.append(Spacer(1, 12))\n",
    "\n",
    "# Format each metrics dict\n",
    "for name, metrics in zip(metric_names, metrics_list):\n",
    "    elements.append(Paragraph(name, styles[\"Heading2\"]))\n",
    "    elements.append(Paragraph(copy[name], styles[\"Normal\"]))\n",
    "    elements.append(Spacer(1, 12))\n",
    "\n",
    "    for k, v in metrics.items():\n",
    "        if isinstance(v, pd.DataFrame):\n",
    "\n",
    "            data = [v.columns.tolist()] + v.values.tolist()  # Include headers\n",
    "            table = Table(data, repeatRows=1)\n",
    "            table.hAlign = 'LEFT'\n",
    "\n",
    "            table.setStyle(TableStyle([\n",
    "                ('BACKGROUND', (0, 0), (-1, 0), colors.lightgrey),\n",
    "                ('GRID', (0, 0), (-1, -1), 0.5, colors.black),\n",
    "                ('FONTNAME', (0, 0), (-1, -1), 'Helvetica'),\n",
    "                ('FONTSIZE', (0, 0), (-1, -1), 10),\n",
    "                ('ALIGN', (0, 0), (-1, -1), 'LEFT'),\n",
    "            ]))\n",
    "            elements.append(Paragraph(k, styles['Normal']))\n",
    "            elements.append(Spacer(1, 12))\n",
    "\n",
    "            elements.append(table)\n",
    "            elements.append(Spacer(1, 12))\n",
    "        else:\n",
    "            text = f\"<b>{k}:</b> {v}\" if isinstance(v, float) else f\"<b>{k}:</b> {v}\"\n",
    "            elements.append(Paragraph(text, styles[\"Normal\"]))\n",
    "    elements.append(Spacer(1, 12))\n",
    "\n",
    "    # images\n",
    "    folder = \"report_images\"\n",
    "    image_keyword = name.lower()\n",
    "    if os.path.exists(folder):\n",
    "        for fname in sorted(os.listdir(folder)):\n",
    "            if image_keyword in fname.lower() and subject in fname:\n",
    "                image_path = os.path.join(folder, fname)\n",
    "\n",
    "                # get dimensions\n",
    "                image_reader = ImageReader(image_path)\n",
    "                orig_width, orig_height = image_reader.getSize()\n",
    "                print(orig_width, orig_height)\n",
    "                if orig_width > 4000:\n",
    "                    img = Image(image_path, width=orig_width/9, height=orig_height/9)\n",
    "                elif orig_width > 3000:\n",
    "                    img = Image(image_path, width=orig_width/7, height=orig_height/7)\n",
    "                elif orig_width > 2000:\n",
    "                    img = Image(image_path, width = orig_width/5, height = orig_height/5)\n",
    "                elif orig_width > 1400:\n",
    "                    img = Image(image_path, width=orig_width/3, height=orig_height/3)\n",
    "                else:\n",
    "                    img = Image(image_path, width=orig_width/2, height=orig_height/2)  # Adjust size as needed\n",
    "                elements.append(img)\n",
    "                elements.append(Spacer(1, 12))\n",
    "\n",
    "\n",
    "\n",
    "doc.build(elements, onFirstPage = add_page_number, onLaterPages = add_page_number)\n",
    "print(f'PDF created: {pdf_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modalities and corresponding data\n",
    "metric_names = [\"EEG\", \"ECG\", \"EDA\", \"RSP\", \"MIC\",\"ET\", \"WEBCAM\", \"Stream Durations\", \"LSL\"]\n",
    "metrics_list = [eeg_print, ecg_print, eda_print, rsp_print, mic_print, et_print, webcam_print, duration_print, lsl_print]\n",
    "\n",
    "\n",
    "# PDF structure\n",
    "parent_folder = xdf_filename.split('mobi')[0]\n",
    "pdf_path = f\"{parent_folder}QCReport.pdf\"\n",
    "doc = SimpleDocTemplate(pdf_path, pagesize=A4)\n",
    "elements = []\n",
    "styles = getSampleStyleSheet()\n",
    "\n",
    "# Define subtitle style if not already done\n",
    "subtitle_style = ParagraphStyle(\n",
    "    name=\"Subtitle\",\n",
    "    parent=styles[\"Heading2\"],\n",
    "    fontSize=14,\n",
    "    leading=16,\n",
    "    textColor=\"gray\",\n",
    "    spaceAfter=12,\n",
    "    alignment=1  # Centered\n",
    ")\n",
    "\n",
    "# page number function\n",
    "def add_page_number(canvas, doc):\n",
    "    page_num = f'{canvas.getPageNumber()}'\n",
    "    canvas.setFont(\"Helvetica\", 9)\n",
    "    canvas.drawRightString(570, 20, page_num)  # (x, y) from bottom-left\n",
    "\n",
    "\n",
    "elements.append(Paragraph(f\"Subject Report: {subject}\", styles[\"Title\"]))\n",
    "elements.append(Paragraph(f\"Collection Date: {get_collection_date(xdf_filename)}\", subtitle_style))\n",
    "elements.append(Spacer(1, 12))\n",
    "\n",
    "# Format each metrics dict\n",
    "for name, metrics in zip(metric_names, metrics_list):\n",
    "    elements.append(Paragraph(name, styles[\"Heading2\"]))\n",
    "    elements.append(Paragraph(copy[name], styles[\"Normal\"]))\n",
    "    elements.append(Spacer(1, 12))\n",
    "\n",
    "    for k, v in metrics.items():\n",
    "        if isinstance(v, pd.DataFrame):\n",
    "            data = [v.columns.tolist()] + v.values.tolist()  # Include headers\n",
    "            table = Table(data, repeatRows=1)\n",
    "            table.hAlign = 'LEFT'\n",
    "\n",
    "            table.setStyle(TableStyle([\n",
    "                ('BACKGROUND', (0, 0), (-1, 0), colors.lightgrey),\n",
    "                ('GRID', (0, 0), (-1, -1), 0.5, colors.black),\n",
    "                ('FONTNAME', (0, 0), (-1, -1), 'Helvetica'),\n",
    "                ('FONTSIZE', (0, 0), (-1, -1), 10),\n",
    "                ('ALIGN', (0, 0), (-1, -1), 'LEFT'),\n",
    "            ]))\n",
    "            elements.append(Paragraph(k, styles['Normal']))\n",
    "            elements.append(Spacer(1, 12))\n",
    "\n",
    "            elements.append(table)\n",
    "            elements.append(Spacer(1, 12))\n",
    "        else:\n",
    "            text = f\"<b>{k}:</b> {v}\" if isinstance(v, float) else f\"<b>{k}:</b> {v}\"\n",
    "            elements.append(Paragraph(text, styles[\"Normal\"]))\n",
    "    elements.append(Spacer(1, 12))\n",
    "\n",
    "    # images\n",
    "    folder = \"report_images\"\n",
    "    image_keyword = name.lower()\n",
    "    if os.path.exists(folder):\n",
    "        row_images = []\n",
    "        for fname in sorted(os.listdir(folder)):\n",
    "            if image_keyword in fname.lower() and subject in fname:\n",
    "                image_path = os.path.join(folder, fname)\n",
    "\n",
    "                # get dimensions\n",
    "                image_reader = ImageReader(image_path)\n",
    "                orig_width, orig_height = image_reader.getSize()\n",
    "                if orig_width > 4000:\n",
    "                    img = Image(image_path, width=orig_width/9, height=orig_height/9)\n",
    "                elif orig_width > 3000:\n",
    "                    img = Image(image_path, width=orig_width/7, height=orig_height/7)\n",
    "                elif orig_width > 2000:\n",
    "                    img = Image(image_path, width=orig_width/5, height=orig_height/5)\n",
    "                elif orig_width > 1400:\n",
    "                    img = Image(image_path, width=orig_width/3, height=orig_height/3)\n",
    "                else:\n",
    "                    img = Image(image_path, width=orig_width/2, height=orig_height/2)\n",
    "\n",
    "                # If 'rsp' in image name, add to a row\n",
    "                if 'rsp' in fname.lower():\n",
    "                    img.drawWidth = 250\n",
    "                    img.drawHeight = 200\n",
    "                    row_images.append(img)\n",
    "                    \n",
    "                    if len(row_images) == 2:\n",
    "                        table = Table([row_images], hAlign = 'CENTER', colWidths=[280,280])\n",
    "                        table.setStyle(TableStyle([('ALIGN', (0, 0), (0, -1), 'LEFT')]))\n",
    "                        elements.append(table)\n",
    "                        elements.append(Spacer(1, 12))\n",
    "                        row_images = []\n",
    "\n",
    "                else:\n",
    "                    elements.append(img)\n",
    "                    elements.append(Spacer(1, 12))\n",
    "\n",
    "        # If there's an unmatched image left in the row buffer\n",
    "        if row_images:\n",
    "            elements.append(Table([row_images], hAlign='CENTER', colWidths='*'))\n",
    "            elements.append(Spacer(1, 12))\n",
    "            \n",
    "\n",
    "doc.build(elements, onFirstPage = add_page_number, onLaterPages = add_page_number)\n",
    "print(f'PDF created: {pdf_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mobi-qc-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
